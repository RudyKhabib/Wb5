# Запуск
**В консоли**

git clone https://github.com/RudyKhabib/Wb5.git

gdown "https://drive.google.com/uc?id=1g4sgW8Eja7QSxjQjIqfefvxlc-Kg5UEq" && unzip -d ./ weights.zip

docker build . --tag fastapi

docker compose -d 

**Обращение к эндпоинту**

Представлено в request_template.py

# О итоговом решении

Итоговое решение представляет собой композицию алгоритмов в inference mode: эмбеддинги из дообученного Visual Transformer конкатенируются с эмбеддингами с Word2Vec (BERT показал себя хуже) после easyOCR и отправляются в catboost, который и возвращает результат.

# Подробнее о проекте "Репутация пользователей"
**Задача**

Необходимо разработать алгоритм, позволяющий **отличить допустимые изображений от недопустимых**. Сложность обуславливается тем, что текст может содержаться и на допустимых фотографиях.
Пользователи загружают картинки в раздел "Отзывы". В ряде случаев недобросовестные пользователи используют отзывы для рекламы товаров или услуг.

# 1. Формализация задачи и EDA

В рамках первой части проекта определена опасность данной проблемы для бизнеса и формализована задача:

**Для начала обсудим чем подобный спам может грозить бизнесу:**

Спам, в котором предлагается оставлять хорошие отзывы за какую-то награду, может увеличить количество некорректных отзывов, что может уменьшить лоялность как среди пользовательей, так среди продавцов, из-за чего они могут выбрать площадки конкурентов
Все виды данных спамов могут понизить качество отзывов, из-за чего покупатели не захотят прибегать к опции отзывов и выберут другую площадку.

**Формализация задачи:**

Нужно разработать алгоритм, позволяющий отличать фото отзыва, содержащего спам, от фото, несодержащего. В качестве спама различают фотографии:
1) С рекламным текстом
2) С предложением о заработке денег/вакансиях
3) С просьбой перейти в телеграм-канал
4) C никнеймами в соцсетях
5) С номерами телефонов

**EDA и трансформации**

Сначала был рассмотрен обычный датасет и с применением грейскейл. Затем пробовались визуальные филтры:

- Фильтр порогового значения
- Фильтр контуров
- Фильтр Собеля

Качества фильтров сравнивались визуально, но для проверки был взят оригинальный датасет и датасет после применения фильтра Собеля: прогнал через ResNet50, оригинальный датасет себя показал лучше, в этом мы еще раз убедимся в домашнем задании 2.

# 2. Проработка вариантов решения

На данном этапе (и последующих) в датасете присутствовало большое количество аугментированных изображений, что грозит смещеной оценки метрики при попадании аугментированных изображений в тренировачную и валидационную выборки.
Поэтому необходимо было найти аугментированные изображения.

**Поиск аугментированных изображений в датасете**

В данной работе использовался алгоритм SIFT, так как он достаточно неоптимальный и так как была выдвинута гипотеза, что аугментированные изображения располагаются в датасете преимущественно друг за другом, то изображения сравнивались с восьмью изображениями до и после (в следующих работах алгоритм сравнения улучшался). Все аугментированные изображения отправились в трейн, оставшиеся распределились между трейн и вал. Дизбаланс классов решался с помошью undersampling.

**ResNet50**

Обучил ResNet50 на оригинальном датасете и после применения фильтра Собеля, на оригинальном датасете accuracy 0.846, после фильтра - 0.674 (Для сравнения использовалась только метрика accuracy, так как далее еще будет проверка по easyOCR, да и классы сбалансированы, поэтому она имеет место быть).

**Распознавание слов на изображениях с помощью EasyOcr**

К оригинальному датасету и датасету после фильтра Собеля применялся EayOCR, для считывания слов с изображений. При визуальном сопоставлении списка слов и изображений, easyocr гораздо лучше справился на оригинальном датасете (что неудивительно, так как он наверняка обучался на данных без применения таких фильтров).

**Определение спама по заданным словам с изображения**

В качестве первой наивной модели классификации текстов была рассмотрена модель, которая классифицирует изображений как спам, при наличии слов из списка "плохих слов". Список "плохих слов" был составлен мной при просмотре большого количества спам изображений датасета, в него входят: **"платят", "телег", "тг", "деньги", "работ", "подработк", "скрин",
"tg", "@", "teleg", "bot", "оплат", "пиши", "зарабатыв", "денюж", "вложен", 'ищи'**. Данная модель на оригинальном датасете показала accuracy 0.923, после применения фильтра Собеля - 0.810, поэтому в дальнейших работах использовался оригинальный датасет, так как фильтр Собеля не показал себя ни одной из модели.

**Подведем полный итог**

- Я протестировал 4 решения: ResNet и easyOCR с предположительными спамовыми словами, каждая модель была проверена на оригинальном датасете и на датасете после фильтра Собеля
- ResNet - обычный классификатор, неудивительно, что он показал не очень хороший результат (Оригинальный датасет - 0.846, Фильтр Собеля - 0.674), однако у меня была гипотеза, что контрастность после фильтра Собеля сделает из ResNet неплохой классификатор и для нашего случая, однако гипотеза разбилась вдребезги
- Модель easyOCR с предположительными спамовыми словами учитывает специфику задачи, в этом его большой плюс и результаты это подтверждают (Оригинальный датасет - 0.92, Фильтр Собеля - 0.81), однако спамовые слова лишь предположение, поэтому дальше использовались другие NLP модели
- С помощью алгоритма SIFT были проверены изображения на аугментации, тем самым удалось выявить дупликаты, кроп и другие аугментации на картинках, в дальнейших работах данный алгоритм будет улучшен, а затем и вовсе заменен
- После этого, все картинки, у которых есть "близнецы" с аугментациями были отправлены в трейн, дабы исключить пересечение с валидационной выборкой и научиться распознавать спам на изображениях под разными углами (буквально), затем разделилось на трейн и вал с проверками на пересечения

# 3. Baseline

**Поиск аугментированных изображений в датасете**

В этой работе ускорен алгоритм SIFT поиска аугментаций, благодаря чему получилось проверять окошком в 50 изображений.

**Распознавание слов на изображениях с помощью EasyOcr**

Как и в предыдущей работе использовался EasyOcr для считывания слов с изображений

**Определение спама по заданным словам с изображения**

Для проверки был оставлен данный алгоритм, как в предыдущей работе

**Эмбеддинги Word2Vector**

Был обучен Word2Vector на словах, полученных с изображений с помощью easyocr, и получены их эмбеддинги

**Классификация с помощью Logreg, RandomForest, CatBoost**

Эмбеддинги из Word2Vector были отправлены в Logreg, RandomForest, CatBoost при базовых параметрах и сравнивались результаты (представлены ниже).

**Подведем полный итог**

В качестве baselines были выбраны комбинации моделей: Ru/Ru-Eu easyOCR * Классификатор по "плохим" словам/(word2vec + LogReg/Random Forest/CatBoost).

Метрикой качества была выбрана F1-мера, так как она устойчива к несбалансированности классов (как всегда происходит в задачах со спамом) и позволяет учитывать баланс между precision и recall, что так же важно, чтобы поймать баланс между поимкой спама среди спамов и ложного отправления в спам среди обычных отзывов.

Итого, лучший по f1 baseline: Ru-Eu OCR + word2vec + CatBoost, c f1 =0.9099449738290162

# 4. Оптимизация решения

**Поиск аугментированных изображений в датасете**

Так как с помощью предыдущего алгоритма получалось сравнивать изображение только с 50 изображениями до него и после, в данной работе использовался другой алгоритм: скачал предобученный мобилнет, получил из него эмбеддинги изображений и сравнивались между собой с помощью Faiss.

**Эмбеддинги Visual Transformer**

Дообучил Visual Transformer на датасете и получил эмбеддинги

**Распознавание слов на изображениях с помощью EasyOcr**

Также как и раньше применял easyocr для считывания текста с изображений

**Эмбеддинги из BERT**

Скачал предобученный BERT и получил эмбеддинги текстов изображений

**Эмбеддинги Word2Vector**

Был обучен Word2Vector на словах, полученных с изображений с помощью easyocr, и получены их эмбеддинги

**Композиция моделей. Градиентный бустинг**

Тьюнился catboost на валидационных данных для моделей: конкатенация Vit эмбеддингов и эмбеддингов W2V после easyocr, конкатенация Vit эмбеддингов и эмбеддингов BERT после easyocr.

Лучшим на submission оказался ViT + easyocr + W2V + catboost с параметрами depth = 8, learning_rate = 0.03, iterations = 1500

**Подведем полный итог**

Тьюнилось две композиции моделей: catboost для конкатенация Vit эмбеддингов и эмбеддингов W2V после easyocr, catboost для конкатенация Vit эмбеддингов и эмбеддингов BERT после easyocr.

Лучшим оказался  ViT + easyocr + W2V + catboost с ROC AUC 0.97885 на тестовых данных.

# Production

Использовался инференс лучшей композиции модели с предыдущей работы: веса ViT для получения эмбединнгов, веса W2V для получения эмбеддингов (использовался после easyocr), веса catboost, куда подавалась конкатенация эмбеддингов после ViT и W2V

**Эндпоинт**

Код для эндпоинтов был написан с помощью FastAPI.

**Веса моделей**

Скачиваются с облака 

**Docker**

Dockerfile и docker-compose предтавлены в репозитории

**Post запрос**

Шаблон представлен в репозитории request_template.py
